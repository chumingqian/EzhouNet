

å°†ä¸‹é¢çš„è¯­å¥ç¿»è¯‘æˆè‹±æ–‡ï¼Œ ä½¿å…¶æˆä¸º github é¦–é¡µä¸­çš„ ReadMe,  å°½é‡ä¿æŒå…¶å‹å¥½é˜…è¯»çš„è¯­æ°”ï¼Œ å¯ä»¥è®¾ç½®åˆç†çš„æŽ’ç‰ˆä¸Žæ’å›¾

# 1. introduction

è¿™ä¸ªä»“åº“æä¾›äº†ä¸€ä¸ªç«¯åˆ°ç«¯æ·±åº¦å­¦ä¹ æ¡†æž¶ç”¨äºŽå£°éŸ³äº‹ä»¶æ£€æµ‹ï¼Œ å¹¶ä¸”æˆ‘ä»¬å°†å…¶åº”ç”¨äºŽå‘¼å¸éŸ³çš„å£°éŸ³äº‹ä»¶æ£€æµ‹ï¼Œ

æˆ‘ä»¬å€Ÿé‰´äº†è®¡ç®—æœºè§†è§‰ä¸­å…ˆéªŒæ¡†çš„æ¦‚å¿µï¼Œ å°†å…ˆéªŒæ¡†çš„è®¾è®¡ä»¥åŠåŒºé—´åç§»é‡å¯å­¦ä¹ çš„æ€æƒ³å¼•å…¥åˆ°å…¶ä¸­ã€‚

é€šè¿‡åœ¨æ•°æ®ç”Ÿæˆé˜¶æ®µä½¿ç”¨desed_task/dataio/datasets_resp_v9_8_7.pyï¼š RespiraGnnSet(Dataset) è¯¥ç±»ä¸­çš„ generate_anchor_intervals å‡½æ•°æ¥ç”Ÿæˆå…ˆéªŒåŒºé—´ï¼Œ  å¹¶åœ¨ç½‘ç»œæ¨¡åž‹ä¸­é€šè¿‡ desed_task/nnet/EzhouNet_v9_7_9.pyï¼š GraphRespiratory(nn.Module):  Interval_Refine æ¨¡å—æ¥å­¦ä¹ å…ˆéªŒåŒºé—´çš„åç§»é‡ï¼Œ

é€šè¿‡ä¸Šè¿°æ–¹å¼ï¼Œæˆ‘ä»¬å®žçŽ°äº†å£°éŸ³äº‹ä»¶åŒºé—´çš„å¯å­¦ä¹ ï¼Œ  ä»Žè€Œé¿å…äº†ä½¿ç”¨å¸§çº§åˆ«çš„åŽå¤„ç†æ–¹å¼æ¥ç”Ÿæˆäº‹ä»¶çš„åŒºé—´ï¼Œéœ€è¦è¯´æ˜Žçš„æ˜¯ï¼Œå°½ç®¡è¿™ç§ç«¯åˆ°ç«¯çš„å£°éŸ³äº‹ä»¶æ£€æµ‹çš„æ–¹å¼è¢«è¯æ˜Žæ˜¯æœ‰æ•ˆçš„ï¼Œ ä½†åœ¨æˆ‘ä»¬çš„å‘¼å¸éŸ³å£°éŸ³äº‹ä»¶æ£€æµ‹çš„åœºæ™¯ä¸­ï¼Œ å½“å‰çš„æ•ˆæžœå´è¿œæ²¡æœ‰è¾¾åˆ°ä¸´åºŠä½¿ç”¨çš„é˜¶æ®µï¼Œ è¿™é‡Œåªæ˜¯æä¾›äº†ä¸€ä¸ªå‚è€ƒç»™åŽç»­çš„ç ”ç©¶è€…ï¼Œ    æ›´å¤šçš„è®¾è®¡åŽŸç†å¯ä»¥å‚è€ƒè®ºæ–‡ï¼ŒåŒæ · éœ€è¦è¯´æ˜Žçš„æ˜¯ï¼Œè¿™ç¯‡è®ºæ–‡ä»…ç”¨äºŽå‚è€ƒè®¾è®¡åŽŸç†çš„ç†è§£ï¼Œ  åœ¨æ–‡ç« æŠ•ç¨¿ä¹‹åŽï¼Œ æˆ‘ä»¬æ›´æ–°è®¸å¤šæ¨¡å—çš„ç»„ä»¶ï¼Œ ç”¨äºŽæ›´å¥½çš„è®­ç»ƒä¼˜åŒ–ã€‚





# 2. getting  started



1.  é¦–å…ˆ å‚è€ƒè¿™ä¸ªä»“åº“ï¼ˆhttps://github.com/DCASE-REPO/DESED_taskï¼‰ä¸­çš„æ­¥éª¤å®‰è£…å¥½ å£°éŸ³äº‹ä»¶æ£€æµ‹è¯„ä»·å‡½æ•°ï¼Œ ç”¨äºŽåŽç»­è¯„ä¼°å£°éŸ³äº‹ä»¶çš„æ£€æµ‹æŒ‡æ ‡ï¼›
2.  å®‰è£… python=3.8;  pytorch-1.13.1;     pytorch-lightningâ€“2.2.5 ;    torch_geometricâ€“2.5.2;   å®‰è£…æ‰€æœ‰çš„ä¾èµ– pip  install -r  requirements.txt
3.   å‡†å¤‡å¥½ä½ ä»»åŠ¡åœºæ™¯ä¸‹å£°éŸ³äº‹ä»¶æ£€æµ‹çš„æ•°æ®é›†ï¼›  åœ¨æˆ‘ä»¬çš„å‘¼å¸éŸ³çš„åœºæ™¯ä¸­ï¼Œ  æˆ‘ä»¬ä½¿ç”¨  SPRsound   ä»¥åŠ   HF Lung V1  è¿™ä¸¤ä¸ªæ•°æ®é›†ï¼›



è®­ç»ƒè„šæœ¬ 

1.    åŸºäºŽå…ˆéªŒåŒºé—´ï¼Œ å­¦ä¹ åŒºé—´åˆå§‹åç§»é‡ä»¥åŠç»“æŸåç§»é‡çš„æ–¹å¼ï¼Œ   å¯ä»¥é€šè¿‡è®¾ç½® requires_grad = False or True   æ¥æŽ§åˆ¶åŸºç¡€åç§»é‡æ˜¯å¦æ˜¯å¯å­¦ä¹ çš„ã€‚ 

   ```
           self.start_weight_params = nn.ParameterList([
               nn.Parameter(torch.linspace(-1.50, 1.50, dist_bins_list[i]), requires_grad= False)
               for i in range(self.num_scales)
           ])
           self.end_weight_params = nn.ParameterList([
               nn.Parameter(torch.linspace(-1.50, 1.50, dist_bins_list[i]), requires_grad= False)
               for i in range(self.num_scales)
           ])
   ```

  

```
python 
```

2.  ç±»ä¼¼äºŽ yolo ä¸­çš„æ€æƒ³ï¼Œ  å­¦ä¹ åŒºé—´ä¸­å¿ƒç‚¹çš„åç§»é‡ï¼Œ ä»¥åŠåŒºé—´å®½åº¦çš„åç§»é‡ï¼›

```
            a_w = (ends - starts).clamp(min=1e-6)  #  width for the anchor interval, seconds
            a_c = 0.5 * (starts + ends)  #  center for the anchor interval

            pred_centers = a_c + t_c_pred * a_w
            pred_widths = a_w * torch.exp(t_w_pred.clamp(min=-6.0, max=6.0))

            s = (pred_centers - 0.5 * pred_widths).clamp(min=0.0, max=float(audio_len))
            e = (pred_centers + 0.5 * pred_widths).clamp(min=0.0, max=float(audio_len))
```





â€‹          3.  å°†ä¸­å¿ƒç‚¹åç§»é‡çš„æ–¹å¼ ä¸Žèµ·å§‹ç»ˆæ­¢ä½ç½®åç§»é‡çš„æ–¹å¼ç»“åˆèµ·æ¥ï¼›

â€‹          python   train_respiratory_lab10_1_3.py



åœ¨å‘¼å¸éŸ³çš„å£°éŸ³äº‹ä»¶çš„æ£€æµ‹ä»»åŠ¡ä¸Šï¼Œ å½“å‰æ–¹æ³•å¯ä»¥èŽ·å¾—çš„æ•ˆæžœå¦‚ä¸‹ï¼š





#   3.further  step

å¯¹äºŽåŽç»­ï¼Œ å¦‚æžœæƒ³åŸºäºŽè¿™ä¸ªå·¥ä½œè¿›è¡Œæ”¹è¿›çš„è¯ï¼Œ ä¸ªäººå»ºè®®å¯ä»¥ä»Žå¦‚ä¸‹çš„ä¸‰ä¸ªæ–¹é¢è¿›è¡Œæ”¹è¿›ï¼š

1.   è¯•ç€å°è¯•åŽ»é™¤å¯¹ç‰¹å¾å›¾è¿›è¡Œå¾ªçŽ¯åˆ‡ç‰‡çš„æ–¹å¼ï¼Œ  å°½ç®¡åˆ†ç»„ç‰¹å¾æå–æ˜¯æœ¬å·¥ä½œçš„å…³é”®ç‚¹ä¹‹ä¸€ï¼Œ  ä½†æ˜¯è¿™ç§åœ¨ç¥žç»ç½‘ç»œæž¶æž„ä¸­åº”ç”¨å¾ªçŽ¯åˆ‡ç‰‡çš„æ–¹å¼ï¼Œ  æ˜¯æžå…¶ä¸åˆ©äºŽå¯¹è¯¥ç½‘ç»œè¿›è¡Œé‡åŒ–ï¼Œéƒ¨ç½²åˆ°ç”Ÿäº§çŽ¯å¢ƒä¸­ã€‚
2.  å¯¹äºŽå‘¼å¸éŸ³ç‰¹å¾çš„é€‰æ‹©ï¼Œ å¯ä»¥å°è¯•æŒ‰ç…§è¿™ç¯‡æ–‡ç« ä¸­çš„æ€è·¯ï¼ˆBenchmarking of eight recurrent
   neural network variants for breath phase and adventitious sound detection on
   a self-developed open-access lung sound databaseâ€”hf_lung_v1)    é€‰æ‹©è¯­è°±å›¾ï¼Œ MFCCs,   èƒ½é‡å’Œè¿›è¡Œç»Ÿè®¡ã€‚
3.  å¯¹äºŽç‰¹å¾èŠ‚ç‚¹çš„æ›´æ–°ï¼Œ å¯ä»¥å°è¯•ä½¿ç”¨å¤šå°ºåº¦å›¾å·ç§¯ multi-scale graph convolutional networksï¼ˆhttps://github.com/xuyuankun631/IcicleGCNï¼‰ï¼Œï¼ˆhttps://github.com/Eydcao/BSMS-GNNï¼‰ ä»¥åŠ Scalable Graph Learningï¼ˆhttps://github.com/PKU-DAIR/SGLï¼‰  æ›¿æ¢åŽŸæ¥çš„GAT æ¨¡å—æ¥æ›´æ–°èŠ‚ç‚¹ç‰¹å¾ã€‚





# Wanna say

æœ¬æ–‡çš„çµæ„Ÿæ˜¯æºäºŽï¼Œåœ¨é„‚å·žç§‘ç ”æœŸé—´åŽ»å‚åŠ äº†ä¸€åœºç”Ÿç‰©åŒ»å­¦çš„ä¼šè®®ï¼Œ   çœ‹åˆ°äº†å›¾ç¥žç»ç½‘ç»œæž¶æž„è¢«å¹¿æ³›åº”ç”¨äºŽç”Ÿç‰©ä¿¡å·çš„å¤„ç†ï¼Œå› æ­¤ï¼Œæˆ‘ä»¬ä¹Ÿæƒ³å°è¯•å°†å…¶åº”ç”¨äºŽå‘¼å¸éŸ³ä¿¡å·ï¼Œ å¹¸è¿çš„æ˜¯è¿™æˆåŠŸäº†ï¼Œ    è¿™å°±æ˜¯ä¸ºä»€ä¹ˆæˆ‘ä»¬å°†å…¶å‘½åä¸º EzhouNet,   ezhou  æ˜¯è¿™ä¸ªåŸŽå¸‚çš„åå­—ã€‚



åœ¨é„‚å·žè¿›è¡Œç§‘ç ”çš„è¿™æ®µæœŸé—´ï¼Œ æˆ‘è®¤è¯†äº†ä¸€ä½æœ‹å‹kunï¼Œ ä»–å¸¦æˆ‘åŽ»è§‚å…‰äº†æ¢å­æ¹–ï¼Œ   kun  è¯´é“ï¼Œ  ä¸–äººåªçŸ¥ æ­¦æ±‰ä¸œæ¹–ï¼Œ å´ä¸çŸ¥é„‚å·ž æ¢å­æ¹–ï¼Œ è¿™é‡Œç¡®å®žæ˜¯ä¸€ä¸ªç”Ÿæ€è‰¯å¥½çš„æ –æ¯åœ°ã€‚





Happy  coding  and  good luck  with your  project.









```
Using confidence threshold: conf=0.501
Category-specific NMS IoU thresholds:
  Stridor: 0.5
  Wheeze: 0.4
  Crackle: 0.15
  Rhonchi: 0.3
	 call the compute event based metrics  

the Event based overall   f score: 0.19796610169491524, 	 error rate : 2.3084479371316307

the Event based class wise average f score: 0.1848416711564406,	 error rate : 2.966633604392851

  Class-wise metrics
  ======================================
    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |
    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |
    Rhonchi      | 29      94    | 14.6%  9.6%   31.0%   | 3.62   0.69   2.93    |
    Stridor      | 5       18    | 17.4%  11.1%  40.0%   | 3.80   0.60   3.20    |
    Crackle      | 287     496   | 17.4%  13.7%  23.7%   | 2.25   0.76   1.49    |
    Wheeze       | 188     358   | 24.5%  18.7%  35.6%   | 2.19   0.64   1.55    |

Using confidence threshold: conf=0.65
Category-specific NMS IoU thresholds:
  Stridor: 0.5
  Wheeze: 0.4
  Crackle: 0.15
  Rhonchi: 0.3
	 call the compute event based metrics  

the Event based overall   f score: 0.20275862068965514, 	 error rate : 2.257367387033399

the Event based class wise average f score: 0.19081504850632036,	 error rate : 2.8438182069170024

  Class-wise metrics
  ======================================
    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |
    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |
    Rhonchi      | 29      88    | 15.4%  10.2%  31.0%   | 3.41   0.69   2.72    |
    Stridor      | 5       17    | 18.2%  11.8%  40.0%   | 3.60   0.60   3.00    |
    Crackle      | 287     486   | 17.9%  14.2%  24.0%   | 2.21   0.76   1.45    |
    Wheeze       | 188     350   | 24.9%  19.1%  35.6%   | 2.15   0.64   1.51    |

Using confidence threshold: conf=0.8
Category-specific NMS IoU thresholds:
  Stridor: 0.5
  Wheeze: 0.4
  Crackle: 0.15
  Rhonchi: 0.3
	 call the compute event based metrics  

the Event based overall   f score: 0.20889202540578686, 	 error rate : 2.1886051080550097

the Event based class wise average f score: 0.20316344967739192,	 error rate : 2.6116479647528896

  Class-wise metrics
  ======================================
    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |
    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |
    Rhonchi      | 29      82    | 16.2%  11.0%  31.0%   | 3.21   0.69   2.52    |
    Stridor      | 5       14    | 21.1%  14.3%  40.0%   | 3.00   0.60   2.40    |
    Crackle      | 287     479   | 18.3%  14.6%  24.4%   | 2.18   0.76   1.43    |
    Wheeze       | 188     333   | 25.7%  20.1%  35.6%   | 2.06   0.64   1.41    |
```





--------------

Hereâ€™s a polished **README.md** draft in English for your GitHub homepage. I kept it **friendly, clear, and structured**, with some Markdown formatting and light illustrative elements (like emoji for readability).

------



# Introduction 

ðŸŽ‰    Welcome to **EzhouNet** . This repository provides an **end-to-end deep learning framework** for **sound event detection (SED)**.   We focus on **respiratory sound events **, and the idea was inspired by **anchor boxes in computer vision**.  

Instead of using frame-level post-processing, we directly **learn event intervals** by:  
- Generating **anchor intervals** with  
  `desed_task/dataio/datasets_resp_v9_8_7.py â†’ RespiraGnnSet(Dataset).generate_anchor_intervals`  
- Refining interval offsets with  
  `desed_task/nnet/EzhouNet_v9_7_9.py â†’ GraphRespiratory(nn.Module).Interval_Refine`  

âš   Please note: while this method has been shown effective for sound event detection,   in the **respiratory sound detection** scenario, it is **not yet ready for clinical use**.  
And this repo serves as a **reference implementation** for researchers.  The original design principles are detailed in our paper, though many modules have since been updated.

---



# ðŸš€ Getting Started

1. Install the **evaluation functions** following the steps in [DESED_task](https://github.com/DCASE-REPO/DESED_task).  
   These will be used to compute  sound event  detection metrics.
2. Set up your environment:  
   - `python=3.8`  
   - `pytorch=1.13.1`  
   - `pytorch-lightning=2.2.5`  
   - `torch_geometric=2.5.2`  
   - Install dependencies:  
     ```bash
     pip install -r requirements.txt
     ```
3. Prepare your dataset.  
   - For respiratory sounds, we used **SPRsound** and **HF Lung V1**.

---

## ðŸ‹ï¸ Training



cd  into  the this path :

```
/Respira_SED_LGNN/recipes/dcase2023_task4_baseline/
```



### 1. Learn start & end offsets of anchor intervals  

Set `requires_grad=True` or `False` to control whether bins  are learnable:
```python
self.start_weight_params = nn.ParameterList([
    nn.Parameter(torch.linspace(-1.50, 1.50, dist_bins_list[i]), requires_grad=False)
    for i in range(self.num_scales)
])
self.end_weight_params = nn.ParameterList([
    nn.Parameter(torch.linspace(-1.50, 1.50, dist_bins_list[i]), requires_grad=False)
    for i in range(self.num_scales)
])
```



```
python   train_respiratory_lab9_8_6.py
```



### 2. YOLO-style learning of center & width offsets

```python
a_w = (ends - starts).clamp(min=1e-6)  # anchor width, seconds
a_c = 0.5 * (starts + ends)            # anchor center

pred_centers = a_c + t_c_pred * a_w
pred_widths = a_w * torch.exp(t_w_pred.clamp(min=-6.0, max=6.0))

s = (pred_centers - 0.5 * pred_widths).clamp(min=0.0, max=float(audio_len))
e = (pred_centers + 0.5 * pred_widths).clamp(min=0.0, max=float(audio_len))
```

```
 python   train_respiratory_lab10_1_2.py
```



### 3. Combine both methods

Mixing center-offset and start/end-offset learning improves detection performance.

```
       python   train_respiratory_lab10_1_3.py
```



here  is  a  reference result:

```
Using confidence threshold: conf=0.501
Category-specific NMS IoU thresholds:
  Stridor: 0.5
  Wheeze: 0.4
  Crackle: 0.15
  Rhonchi: 0.3
	 call the compute event based metrics  

the Event based overall   f score: 0.19796610169491524, 	 error rate : 2.3084479371316307

the Event based class wise average f score: 0.1848416711564406,	 error rate : 2.966633604392851

  Class-wise metrics
  ======================================
    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |
    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |
    Rhonchi      | 29      94    | 14.6%  9.6%   31.0%   | 3.62   0.69   2.93    |
    Stridor      | 5       18    | 17.4%  11.1%  40.0%   | 3.80   0.60   3.20    |
    Crackle      | 287     496   | 17.4%  13.7%  23.7%   | 2.25   0.76   1.49    |
    Wheeze       | 188     358   | 24.5%  18.7%  35.6%   | 2.19   0.64   1.55    |

Using confidence threshold: conf=0.65
Category-specific NMS IoU thresholds:
  Stridor: 0.5
  Wheeze: 0.4
  Crackle: 0.15
  Rhonchi: 0.3
	 call the compute event based metrics  

the Event based overall   f score: 0.20275862068965514, 	 error rate : 2.257367387033399

the Event based class wise average f score: 0.19081504850632036,	 error rate : 2.8438182069170024

  Class-wise metrics
  ======================================
    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |
    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |
    Rhonchi      | 29      88    | 15.4%  10.2%  31.0%   | 3.41   0.69   2.72    |
    Stridor      | 5       17    | 18.2%  11.8%  40.0%   | 3.60   0.60   3.00    |
    Crackle      | 287     486   | 17.9%  14.2%  24.0%   | 2.21   0.76   1.45    |
    Wheeze       | 188     350   | 24.9%  19.1%  35.6%   | 2.15   0.64   1.51    |

Using confidence threshold: conf=0.8
Category-specific NMS IoU thresholds:
  Stridor: 0.5
  Wheeze: 0.4
  Crackle: 0.15
  Rhonchi: 0.3
	 call the compute event based metrics  

the Event based overall   f score: 0.20889202540578686, 	 error rate : 2.1886051080550097

the Event based class wise average f score: 0.20316344967739192,	 error rate : 2.6116479647528896

  Class-wise metrics
  ======================================
    Event label  | Nref    Nsys  | F        Pre      Rec    | ER       Del      Ins    |
    ------------ | -----   ----- | ------   ------   ------ | ------   ------   ------ |
    Rhonchi      | 29      82    | 16.2%  11.0%  31.0%   | 3.21   0.69   2.52    |
    Stridor      | 5       14    | 21.1%  14.3%  40.0%   | 3.00   0.60   2.40    |
    Crackle      | 287     479   | 18.3%  14.6%  24.4%   | 2.18   0.76   1.43    |
    Wheeze       | 188     333   | 25.7%  20.1%  35.6%   | 2.06   0.64   1.41    |
```



------

# ðŸ”® Further Steps

If youâ€™d like to improve upon this work, here are some suggestions:

1. **Avoid  group  cyclic slicing** of  spectrogram feature maps.
    While useful for grouped feature extraction, it makes quantization & deployment difficult.
2. **Try alternative respiratory features**:
    spectrograms, MFCCs, energy, or statistical features (see the paper  *Benchmarking of eight RNN variants for breath phase and adventitious sound detection on hf_lung_v1*).
3. **Explore advanced  multi scale graph convolution modules**    for node updates , e.g.:
   - [IcicleGCN](https://github.com/xuyuankun631/IcicleGCN)
   - [BSMS-GNN](https://github.com/Eydcao/BSMS-GNN)
   - [Scalable Graph Learning](https://github.com/PKU-DAIR/SGL)

------

# ðŸ’¡ Inspiration

The idea came  a biomedical conference in  the University,   where I saw **graph neural networks**  being widely applied to biosignals.   Thatâ€™s how **EzhouNet** was born â€” named after the city of **Ezhou**.

During the  research time in Ezhou, I met a friend there, Kun, who took me to visit Liangzi Lake. He said:

> â€œPeople knows Wuhanâ€™s East Lake, but few know Liangzi Lake in Ezhou.â€
>  It truly is an ecological gem. ðŸŒ¿ðŸŒŠ

------



   Feel free to fork, experiment, and improve your  lab.   Happy coding, and good luck with your projects! ðŸš€
        



![liangzi1](/home/respecting_god/Downloads/liangzi1.png)

![liangzi2](/home/respecting_god/Downloads/liangzi2.png)